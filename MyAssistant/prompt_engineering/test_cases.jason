{
  "test_cases": [
    {
        "id": "TC-001",
        "name": "Invalid Query Handling",
        "input": {
          "query": "asdkjfhaskjdfh",
          "documents": [],
          "chat_history": [],
          "mentions": []
        },
        "golden_output": {
          "content": "It seems like you entered a string of random characters. How can I assist you today? If you have any questions or need information, feel free to ask!",
          "references": []
        }
      },
      {
        "id": "TC-002",
        "name": "React Component Structure",
        "input": {
          "query": "What's the best way to structure React components in our codebase?",
          "documents": [],
          "chat_history": [],
          "mentions": []
        },
        "golden_output": {
          "content": "Structuring React components effectively in a codebase is crucial for maintaining scalability, readability, and ease of maintenance. Here are some best practices and strategies to consider when organizing your React components:\n\n### 1. **Component Folder Structure**\n\n#### a. **Feature-based Structure**\nOrganize by feature or domain rather than by file type. This approach focuses on encapsulating all related files (components, tests, styles) for a single feature in one directory.\n\n```\n/src\n  /components\n    /Button\n      - index.jsx\n      - Button.test.jsx\n      - Button.css\n  /features\n    /Todo\n      - TodoList.jsx\n      - TodoItem.jsx\n      - TodoAPI.js\n      - TodoList.test.jsx\n      - Todo.css\n```\n\n#### b. **Atomic Design**\nThis methodology, proposed by Brad Frost, involves breaking down your UI into fundamental building blocks (atoms, molecules, organisms, templates, and pages) and theming them together hierarchically.\n\n```\n/src\n  /atoms\n    /Button\n    /Input\n  /molecules\n    /SearchBar\n    /UserCard\n  /organisms\n    /Header\n    /Footer\n  /templates\n    /PageTemplate\n  /pages\n    /HomePage\n    /ProfilePage\n```\n\n### 2. **Naming Conventions**\n- **Component Names**: Use PascalCase for component files and their respective folders (if applicable). Example: `ReservationCard.jsx`\n- **Test Files**: Suffix test files with `.test` or `.spec`. Example: `ReservationCard.test.jsx`\n- **Stylesheet Files**: Keep styles close to components if they are component-specific. Example: `ReservationCard.module.css`\n\n### 3. **Hierarchy and Composition**\n- **Stateful and Stateless Components**: Separate your UI components (stateless/presentational) from containers (stateful/logic-driven). This separation helps in reusing UI components.\n- **Higher-Order Components (HOCs)**: Utilize HOCs for enhancing component features without modifying their actual code.\n- **Hooks**: Use custom hooks for extracting and reusing logic across components.\n\n### 4. **Reusable Components**\nDevelop a library of reusable components. This practice reduces code duplication and increases the consistency of the UI/UX across your application.\n\n### 5. **Testing**\nKeep your test files next to their respective component files. This approach makes it easier to manage and update tests alongside component changes.\n\n### 6. **Documentation**\nDocument components using tools like Storybook or Styleguidist. This documentation acts as a living style guide and promotes better understanding and reuse of components.\n\n### 7. **Performance Optimization**\n- **Code Splitting**: Use dynamic `import()` syntax to split code into chunks and reduce the size of the initial load.\n- **Memoization**: Utilize `React.memo`, `useMemo`, and `useCallback` to prevent unnecessary re-renders and computations.\n\n### 8. **Use of Context and State Management**\nFor global state management, consider using Context API for simpler states or adopting more robust solutions like Redux or MobX for larger applications.\n\n### 9. **Accessibility (a11y)**\nEnsure components follow accessibility standards. Use semantic HTML and ARIA roles where applicable.\n\n### 10. **Internationalization (i18n)**\nPlan for internationalization if your application targets multiple languages or regions.\n\nBy adopting these strategies, you can create a React codebase that is modular, easy to maintain, and scalable. Each project may have unique requirements, so adapt these guidelines as needed to fit your specific context.",
          "references": ["model.json"]
        }
      },
      {
        "id": "TC-003",
        "name": "Code Review with Document Context",
        "input": {
          "query": "Review this Python code for compliance with our standards.",
          "documents": ["code_sample.py"],
          "chat_history": [],
          "mentions": []
        },
        "golden_output": {
          "content": "The provided Python code snippet demonstrates a simple function for division with error handling. Here's a review based on common coding standards and best practices for Python:\n\n### Code Review\n\n#### code_sample.py:\n\n```python\ndef divide(a, b):\n    try:\n        result = a / b\n    except ZeroDivisionError:\n        print(\"Error: Division by zero is not allowed.\")\n        result = None\n    return result\n```\n\n### Compliance with Standards\n\n1. **Function Documentation:**\n   - **Issue**: The function lacks a docstring, which is important for documentation and readability.\n   - **Recommendation**: Add a docstring to explain the function's purpose, parameters, and return value.\n\n2. **Exception Handling:**\n   - **Observation**: The function correctly handles the `ZeroDivisionError` by catching the exception and printing an error message.\n   - **Recommendation**: Consider logging the error instead of printing, or raise a custom exception after handling to inform the caller of the issue.\n\n3. **Print Statement:**\n   - **Issue**: Using `print` for error messages is not recommended in production code.\n   - **Recommendation**: Use the `logging` module to log an error message, which offers more flexibility and control over how messages are handled and recorded.\n\n4. **Return Value:**\n   - **Observation**: The function returns `None` in case of an error.\n   - **Recommendation**: Ensure that the return of `None` is handled properly by the function callers. Alternatively, consider raising an exception with a message indicating the issue.\n\n5. **Type Annotations:**\n   - **Issue**: The function parameters and return type are not annotated.\n   - **Recommendation**: Use Python's type hints to improve code readability and help with static analysis:\n     ```python\n     def divide(a: float, b: float) -> float:\n     ```\n\n6. **Naming Conventions:**\n   - **Observation**: The function and variable names are clear and descriptive.\n   - **Recommendation**: Maintain this practice; no changes needed here.\n\n### Updated Code with Recommendations\n\nHere’s how the code can be improved based on the suggestions:\n\n```python\nimport logging\n\ndef divide(a: float, b: float) -> float:\n    \"\"\"\n    Divides two numbers and handles division by zero.\n\n    Parameters:\n    a (float): The numerator.\n    b (float): The denominator.\n\n    Returns:\n    float: The result of the division if no error occurs, otherwise None.\n\n    Raises:\n    ValueError: If division by zero is attempted.\n    \"\"\"\n    try:\n        result = a / b\n    except ZeroDivisionError:\n        logging.error(\"Division by zero attempted.\")\n        raise ValueError(\"Division by zero is not allowed.\")\n    return result\n```\n\n### Final Notes\n\n- **Error Handling**: Raising an exception after logging allows the caller to handle the exception accordingly and is a common practice in libraries and larger applications.\n- **Logging**: Configure the logging as per the application's needs, setting the appropriate level and format.\n\nThis review ensures that the `divide` function is robust, easier to maintain, and integrates well in a larger Python application or library with standard practices.",
          "references": ["code_sample.py", "model.json"]
        }
      },
      {
        "id": "TC-004",
        "name": "Database Pattern with Previous Chat Context",
        "input": {
          "query": "How should I implement pagination in my Django API endpoint?",
          "documents": [],
          "chat_history": [
            {"role": "user", "content": "I'm building a Django REST API for our product catalog."},
            {"role": "assistant", "content": "That's great! Django REST framework is our recommended approach for building APIs at Oakie Technologies. What specific aspect of the API are you working on?"}
          ],
          "mentions": []
        },
        "golden_output": {
          "content": "Implementing pagination in a Django API endpoint is important for handling large datasets efficiently by breaking the data into smaller, manageable chunks. This improves the performance of your API and enhances the user experience. Django Rest Framework (DRF) offers several built-in pagination styles that you can easily integrate into your API. Here’s how to do it:\n\n### Step 1: Install Django Rest Framework\nIf you haven't already, you need to install and add Django Rest Framework to your project. You can install it using pip:\n\n```bash\npip install djangorestframework\n```\n\nAdd it to your `INSTALLED_APPS` in `settings.py`:\n\n```python\nINSTALLED_APPS = [\n    ...\n    'rest_framework',\n]\n```\n\n### Step 2: Configure Pagination\nDjango Rest Framework supports various types of pagination. You can configure the pagination globally in your `settings.py` or locally in individual views. Here’s how to set it up globally:\n\n```python\n# settings.py\n\nREST_FRAMEWORK = {\n    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',\n    'PAGE_SIZE': 10  # You can adjust the page size to your preference\n}\n```\n\n### Step 3: Create a View with Pagination\nYou can use DRF's generic views or viewsets which automatically use the pagination settings defined in `settings.py`. Here's an example using a `ViewSet`:\n\n```python\nfrom rest_framework import viewsets\nfrom .models import MyModel\nfrom .serializers import MyModelSerializer\n\nclass MyModelViewSet(viewsets.ModelViewSet):\n    queryset = MyModel.objects.all()\n    serializer_class = MyModelSerializer\n```\n\n### Step 4: Customize Pagination\nIf you need custom pagination for a specific view, you can create a custom pagination class by extending one of DRF’s pagination classes:\n\n```python\nfrom rest_framework.pagination import PageNumberPagination\nfrom rest_framework.response import Response\n\nclass CustomPagination(PageNumberPagination):\n    page_size = 5\n    page_size_query_param = 'page_size'\n    max_page_size = 100\n\n    def get_paginated_response(self, data):\n        return Response({\n            'links': {\n                'next': self.get_next_link(),\n                'previous': self.get_previous_link()\n            },\n            'total': self.page.paginator.count,\n            'page_size': self.page_size,\n            'data': data\n        })\n\n# In your view:\nclass MyModelViewSet(viewsets.ModelViewSet):\n    queryset = MyModel.objects.all()\n    serializer_class = MyModelSerializer\n    pagination_class = CustomPagination\n```\n\n### Step 5: Testing Your API\nAfter setting up pagination, you can test your API endpoint to ensure it works as expected. When accessing the API, you should see the paginated response structure, which includes pagination controls and data.\n\n### Additional Tips\n- **Query Parameters**: Use query parameters like `page` and `page_size` (if enabled) to navigate through pages.\n- **Performance**: For very large datasets, consider using more efficient pagination styles like `CursorPagination` to improve performance.\n- **Frontend Integration**: Ensure your frontend handles pagination data correctly, displaying controls and managing API requests for different pages.\n\nBy following these steps, you can efficiently implement pagination in your Django API endpoints, making them scalable and user-friendly.",
          "references": ["model.json"]
        }
      },
      {
        "id": "TC-005",
        "name": "Error Handling with Explicit Mentions",
        "input": {
          "query": "What's the best way to handle errors in my AWS Lambda function?",
          "documents": [],
          "chat_history": [],
          "mentions": [
            {"role": "user", "content": "I'm writing a Lambda function in Python that processes S3 events."},
            {"role": "assistant", "content": "For AWS Lambda functions, make sure to follow our error handling guidelines to ensure proper monitoring and debugging."}
          ]
        },
        "golden_output": {
          "content": "Handling errors effectively in AWS Lambda functions is crucial for building resilient applications. Error handling not only helps in diagnosing issues during development and in production but also in maintaining the health of your Lambda function during unexpected scenarios. Here are some best practices and strategies to consider when implementing error handling in AWS Lambda, especially when processing S3 events:\n\n### 1. **Understand Lambda Errors**\nAWS Lambda can encounter two types of errors:\n- **Handled Errors**: These occur when your code runs but doesn’t produce the expected result due to an issue in the logic, caught exceptions, or explicit error handling.\n- **Unhandled Errors**: These arise from exceptions that are not caught in the code, causing the Lambda function to terminate prematurely.\n\n### 2. **Use Try-Except Blocks**\nImplement `try-except` blocks in your Python code to catch and handle exceptions that could occur during execution. This is particularly important for operations that are prone to failure, such as network calls, file operations, or data parsing.\n\n```python\nimport json\nimport boto3\n\ndef lambda_handler(event, context):\n    try:\n        # Process the S3 event\n        s3 = boto3.client('s3')\n        for record in event['Records']:\n            bucket = record['s3']['bucket']['name']\n            key = record['s3']['object']['key']\n            response = s3.get_object(Bucket=bucket, Key=key)\n            data = response['Body'].read()\n            # Process data here\n    except Exception as e:\n        print(f\"Error processing S3 event: {str(e)}\")\n        # Optionally: Send error notification\n        raise e  # Rethrowing the exception after logging it\n```\n\n### 3. **Log Detailed Error Information**\nLogging is vital for diagnosing issues. Use AWS CloudWatch to log detailed error information, including the stack trace. Ensure that the logs contain enough context to help you understand the circumstances under which the error occurred.\n\n### 4. **Error Notifications**\nFor critical errors, consider integrating error notifications using AWS SNS (Simple Notification Service), AWS SES (Simple Email Service), or any third-party service like Slack or PagerDuty. This ensures that you or your team can respond to errors promptly.\n\n### 5. **Use Dead Letter Queues (DLQ)**\nConfigure a Dead Letter Queue to capture unprocessed events. This is helpful for debugging and ensures that the data isn't lost. You can analyze the DLQ messages to understand why they weren’t processed successfully.\n\n### 6. **Set Retries and Error Handling Configurations**\nLambda functions retry automatically on unhandled errors when triggered by certain AWS services (like Amazon S3). You can control this behavior by setting a Maximum Retry Attempts or configuring a DLQ in the Lambda function settings.\n\n### 7. **Monitor and Alarms**\nUse AWS CloudWatch to monitor your Lambda functions and set alarms for anomalies such as sudden increases in error rates or function throttling.\n\n### 8. **Unit Testing**\nImplement unit tests to cover various scenarios, including expected failures. Testing helps catch errors early in the development cycle.\n\n### 9. **Validation**\nValidate input data early in the function execution to catch malformed data. This can prevent errors that would otherwise occur deep within your business logic.\n\n### 10. **Graceful Degradation**\nConsider implementing graceful degradation techniques where appropriate. If a non-critical component of your application fails, allow the rest of the application to continue functioning.\n\nBy implementing these error handling strategies, your Lambda functions will be more robust and reliable, ensuring they handle failures gracefully and maintain high availability.",
          "references": ["model.json"]
        }
      },
    {
      "id": "TC-006",
      "name": "Complex Technical Question with All Context Types",
      "input": {
        "query": "How should I implement unit tests for my microservice that handles authentication?",
        "documents": ["auth_service_architecture.md"],
        "chat_history": [
          {"role": "user", "content": "I'm working on the new authentication microservice for our platform."},
          {"role": "assistant", "content": "That's an important component! Are you following our standard JWT-based approach with Redis for token storage?"},
          {"role": "user", "content": "Yes, and I'm adding the refresh token rotation feature we discussed."}
        ],
        "mentions": [
          {"role": "user", "content": "The service needs to handle at least 1000 requests per second."},
          {"role": "assistant", "content": "For high-throughput services like this, we recommend using async testing frameworks like pytest-asyncio."}
        ]
      },
      "golden_output": {
        "content": "# Authentication Microservice Testing Strategy\n\nBased on your architecture document, chat history, and requirements for the authentication microservice with JWT, Redis storage, and refresh token rotation that handles 1000+ requests per second, here's a comprehensive unit testing strategy following Oakie Technologies' standards:\n\n## 1. Test Framework Setup\n\n```python\n# requirements-dev.txt\npytest==7.3.1\npytest-asyncio==0.21.0\npytest-cov==4.1.0\npytest-mock==3.10.0\naiohttp-client-testlib==0.4.0\nredis-mocked==0.5.0\n```\n\n```python\n# conftest.py\nimport pytest\nimport asyncio\nfrom unittest.mock import patch, MagicMock\nfrom redis_mocked import fake_redis\n\n@pytest.fixture\nasync def mock_redis():\n    with fake_redis() as redis:\n        yield redis\n        \n@pytest.fixture\nasync def mock_auth_db():\n    # Setup mock DB for testing\n    db = MagicMock()\n    # Configure mock returns\n    yield db\n    # Teardown if needed\n```\n\n## 2. Unit Test Categories\n\n### 2.1 Token Generation and Validation Tests\n\n```python\n@pytest.mark.asyncio\nasync def test_jwt_token_generation():\n    # Test JWT token generation with correct claims and expiry\n    auth_service = AuthService()\n    user_id = \"user123\"\n    token = await auth_service.generate_token(user_id)\n    \n    # Verify token structure and claims\n    decoded = jwt.decode(token, verify=False)\n    assert decoded[\"sub\"] == user_id\n    assert decoded[\"exp\"] > time.time()\n    assert \"jti\" in decoded  # Token ID for revocation\n\n@pytest.mark.asyncio\nasync def test_token_validation():\n    # Test token validation logic\n    auth_service = AuthService()\n    token = await auth_service.generate_token(\"user123\")\n    result = await auth_service.validate_token(token)\n    \n    assert result[\"valid\"] == True\n    assert result[\"user_id\"] == \"user123\"\n```\n\n### 2.2 Refresh Token Tests\n\n```python\n@pytest.mark.asyncio\nasync def test_refresh_token_rotation(mock_redis):\n    auth_service = AuthService(redis_client=mock_redis)\n    \n    # Generate initial tokens\n    tokens = await auth_service.generate_token_pair(\"user123\")\n    \n    # Mock time passing\n    with patch('time.time', return_value=time.time() + 600):\n        # Test refresh\n        new_tokens = await auth_service.refresh_tokens(tokens[\"refresh_token\"])\n        \n        # Verify old refresh token is invalidated\n        is_blacklisted = await auth_service.is_token_blacklisted(tokens[\"refresh_token\"])\n        assert is_blacklisted == True\n        \n        # Verify new tokens are valid\n        assert new_tokens[\"access_token\"] != tokens[\"access_token\"]\n        assert new_tokens[\"refresh_token\"] != tokens[\"refresh_token\"]\n```\n\n### 2.3 Load Tests (as Unit Tests)\n\n```python\n@pytest.mark.asyncio\nasync def test_token_validation_performance():\n    auth_service = AuthService()\n    token = await auth_service.generate_token(\"user123\")\n    \n    start_time = time.time()\n    tasks = [auth_service.validate_token(token) for _ in range(100)]\n    await asyncio.gather(*tasks)\n    end_time = time.time()\n    \n    # 100 validations should take < 100ms for meeting 1000 rps goal\n    assert end_time - start_time < 0.1\n```\n\n## 3. Mocking External Dependencies\n\n```python\n@pytest.mark.asyncio\nasync def test_user_authentication(mock_auth_db):\n    # Configure mock to return a password hash\n    mock_auth_db.get_user.return_value = {\n        \"user_id\": \"user123\",\n        \"password_hash\": \"$2b$12$LQvXzHGd0Z7HMWs5XB8H8eVYwDq9PdIdUfuxfF8I9XSok889Oj7na\" # 'password'\n    }\n    \n    auth_service = AuthService(db_client=mock_auth_db)\n    result = await auth_service.authenticate_user(\"user@example.com\", \"password\")\n    \n    assert result[\"authenticated\"] == True\n    assert result[\"user_id\"] == \"user123\"\n    assert \"access_token\" in result\n    assert \"refresh_token\" in result\n```\n\n## 4. Edge Cases and Security Tests\n\n```python\n@pytest.mark.asyncio\nasync def test_token_revocation(mock_redis):\n    auth_service = AuthService(redis_client=mock_redis)\n    token = await auth_service.generate_token(\"user123\")\n    \n    # Revoke token\n    await auth_service.revoke_token(token)\n    \n    # Verify token is now invalid\n    result = await auth_service.validate_token(token)\n    assert result[\"valid\"] == False\n    assert result[\"error\"] == \"token_revoked\"\n\n@pytest.mark.asyncio\nasync def test_rate_limiting():\n    rate_limiter = RateLimiter(max_requests=5, time_window=1)  # 5 requests per second\n    \n    # Should allow 5 requests\n    for i in range(5):\n        assert await rate_limiter.check_limit(\"test_ip\") == True\n    \n    # 6th request should be limited\n    assert await rate_limiter.check_limit(\"test_ip\") == False\n```\n\n## 5. CI/CD Integration\n\nAdd this to your `.github/workflows/test.yml` file:\n\n```yaml\nname: Auth Service Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n          pip install -r requirements-dev.txt\n      - name: Run tests with coverage\n        run: |\n          pytest tests/ --cov=auth_service --cov-report=xml\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n```\n\nThis comprehensive testing strategy covers unit tests for all major components while ensuring performance meets your 1000 requests/second requirement. The tests follow our TDD approach and include proper mocking of external dependencies like Redis for token storage.",
        "references": ["auth_service_architecture.md", "model.json"]
      }
    }
  ]
}
